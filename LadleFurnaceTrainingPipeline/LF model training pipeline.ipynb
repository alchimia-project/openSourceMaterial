{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1daee-2358-43ae-81f7-a3baad843968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Lambda\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib widget   # SEMBRA CHE NON FUNZIONI\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pickle import dump\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, root_mean_squared_error, mean_absolute_error\n",
    "from datetime import datetime\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.utils import plot_model\n",
    "import copy\n",
    "\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6358676-18be-45ee-95f3-6c9eeb1e05d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleDataset(x, y, modelName, save=True):\n",
    "    \"\"\" This function scales the input and target data (x, y) \n",
    "    returns the scaled input and target data (x_scaled, y_scaled)\n",
    "    and saves the input and output scalers.\n",
    "    :param x: input dataset\n",
    "    :param y: target dataset\n",
    "    :param modelName: a string with the model name\n",
    "    :param save: save the scalers (True/False), default: True\n",
    "    :return: 1) x_scaled: the scaled input data\n",
    "             2) y_scaled: the scaled output data\n",
    "             3) input_scaler: the input scaler\n",
    "             4) output_scaler: the output scaler\n",
    "    \"\"\"\n",
    "    input_scaler = MinMaxScaler()\n",
    "    output_scaler = MinMaxScaler()\n",
    "    x_scaled = input_scaler.fit_transform(x)\n",
    "    y_scaled = output_scaler.fit_transform(y)\n",
    "    if save:\n",
    "        dump(input_scaler, open(modelName + '_IS.pkl', 'wb'))   # save the input scaler\n",
    "        dump(output_scaler, open(modelName + '_OS.pkl', 'wb'))  # save the output scaler\n",
    "    return x_scaled, y_scaled, input_scaler, output_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e834c4c-01db-40ab-a4cb-cf4e726060e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadScalerAndScaleDataset(filepath, x, y):\n",
    "    \"\"\" This function load the scalers from a pickle file,\n",
    "    scales the input and target data (x, y) \n",
    "    returns the scaled input and target data (x_scaled, y_scaled)\n",
    "    and the input and output scalers.\n",
    "    :param x: input dataset\n",
    "    :param y: target dataset\n",
    "    \n",
    "    :return: 1) x_scaled: the scaled input data\n",
    "             2) y_scaled: the scaled output data\n",
    "             3) input_scaler: the input scaler\n",
    "             4) output_scaler: the output scaler\n",
    "    \"\"\"\n",
    "    input_scaler = pickle.load(open(filepath + \"_InputScaler.pkl\", 'rb'))\n",
    "    output_scaler = pickle.load(open(filepath + \"_OutputScaler.pkl\", 'rb'))\n",
    "    \n",
    "    x_scaled = input_scaler.transform(x)\n",
    "    y_scaled = output_scaler.transform(y)\n",
    "    return x_scaled, y_scaled, input_scaler, output_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8c781-d1ea-4c24-8abc-a745b9cf9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleInputData(x, saveScaler=False, path='LFModel_IS.pkl'):\n",
    "    \"\"\" This function scales only the input data x \n",
    "    returns the scaled input data x_scaled\n",
    "    and saves the input scaler if saveScaler is True\n",
    "    :param x: input dataset\n",
    "    :param saveScaler: flag for saving the scaler\n",
    "    \n",
    "    :return: 1) x_scaled: the scaled input data\n",
    "             2) input_scaler: the input scaler\n",
    "    \"\"\"\n",
    "    input_scaler = MinMaxScaler()\n",
    "    x_scaled = input_scaler.fit_transform(x)\n",
    "\n",
    "    if saveScaler:\n",
    "        dump(input_scaler, open(path, 'wb'))   # save the input scaler\n",
    "    \n",
    "    return x_scaled, input_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f86b67-9ee7-4891-ab17-e5212a743c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq_nn(x_tr, y_tr, neurons, activation, model_name, verbosityLevel, lr=0.0009, patience=10, ModelCheckpoint=False, plot=True, saveModel=True, validationSplit=0.3):\n",
    "    \"\"\" This function trains a Sequential model created through keras\n",
    "    :param x_train: scaled input dataset\n",
    "    :param y_train: scaled target dataset\n",
    "    :param neurons_number: number of neurons defined as a list of ints\n",
    "    :return: 1) trained_model: the trained keras model\n",
    "             2) history: the history of the trained model\n",
    "    \"\"\"\n",
    "    inputs_dimension = x_tr.shape[1]\n",
    "    print(f'The number of inputs is {inputs_dimension}')\n",
    "    output_dimension = y_tr.shape[1]\n",
    "    print(f'The number of outputs is {output_dimension}')\n",
    "\n",
    "    # Build the keras model\n",
    "    trained_model = Sequential()\n",
    "    trained_model.add(Dense(neurons[0], activation=activation, input_dim=inputs_dimension))\n",
    "    \n",
    "    for i in range(1, len(neurons)):\n",
    "        trained_model.add(Dense(neurons[i], activation=activation))\n",
    "    trained_model.add(Dense(output_dimension, activation='linear'))  # tanh\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    trained_model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"mse\"])\n",
    "\n",
    "    es_call = keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    trainingCallbacks = [es_call]\n",
    "    if ModelCheckpoint:\n",
    "        mc_call = keras.callbacks.ModelCheckpoint(model_name + '.h5', monitor='val_loss', mode='min', verbose=verbosityLevel, save_best_only=True)\n",
    "        trainingCallbacks.append(mc_call)\n",
    "    \n",
    "    # Train the model\n",
    "    history = trained_model.fit(x_tr, y_tr,\n",
    "                                epochs=5000, batch_size=32,\n",
    "                                validation_split=validationSplit, callbacks=trainingCallbacks,\n",
    "                                verbose=verbosityLevel)\n",
    "    \n",
    "    MinValidationLoss = min(history.history['val_loss'])\n",
    "\n",
    "    if saveModel:\n",
    "        trained_model.save(model_name + '.keras')\n",
    "    \n",
    "    if plot:\n",
    "        print(f'\\nThe minimum validation loss is: {MinValidationLoss}\\n')\n",
    "        trained_model.summary()\n",
    "        # summarize history for loss\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    return trained_model, history, MinValidationLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f5f62-4917-4093-86c0-61fa3cbfcb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_model(trained_model, inputs):\n",
    "    \"\"\" This function simulate the trained_model\n",
    "    :param trained_model: keras model (trained)\n",
    "    :param inputs: simulation inputs\n",
    "    :return: outputs of the simulated model\n",
    "    \"\"\"\n",
    "    return trained_model.predict(inputs)  # check dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa138017-3263-47a7-82ae-3a485cb004b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAndLinRegression(x, y, targetVar, savePlot, path, fit_intercept_flag=False, xlim=None, ylim=None):\n",
    "    model = LinearRegression(fit_intercept=fit_intercept_flag)\n",
    "    x_r = x.reshape(-1, 1)\n",
    "    y_r = y\n",
    "    model.fit(x_r, y_r)\n",
    "    y_pred = model.predict(x_r)\n",
    "    slope = float(model.coef_) \n",
    "    intercept = float(model.intercept_) \n",
    "    r2score = r2_score(x, y)\n",
    "    equation = f'y = {slope:.2f} x + {intercept:.2f}. R2: {r2score:.3f}'\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.scatter(x, y, label=f'Output {targetVar}', alpha=0.3)\n",
    "    ax.plot(x_r, y_pred, color='red', label='Linear regression')\n",
    "    ax.set_xlabel('Target ' + targetVar)\n",
    "    ax.set_ylabel('Prediction ' + targetVar)\n",
    "    plt.title('Target vs Prediction: ' + targetVar)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.text(0.05, 0.95, equation, transform=ax.transAxes, fontsize=12, color='red',\n",
    "        bbox=dict(facecolor='white', alpha=0.5, edgecolor='none'))\n",
    "    ax.legend(loc='lower right')\n",
    "    if xlim:\n",
    "        plt.xlim(xlim[0], xlim[1])\n",
    "    if ylim:\n",
    "        plt.ylim(ylim[0], ylim[1])\n",
    "    if savePlot:\n",
    "        plt.savefig(path + targetVar + \"_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '.png', dpi=300)\n",
    "    plt.show()\n",
    "    return r2score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0830f98-49a2-4f38-a5e6-8e1aa1442793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(target, simulation, var=None, printScores=True):\n",
    "    r2_scores = []\n",
    "    mse = []\n",
    "    mae = []\n",
    "    rmse = []\n",
    "    if target.ndim > 1:\n",
    "        n_outputs = target.shape[1]\n",
    "        for i_out in range(n_outputs):\n",
    "            r2_scores.append(r2_score(target[:, i_out], simulation[:, i_out])) \n",
    "            mse_i = mean_squared_error(target[:, i_out], simulation[:, i_out])\n",
    "            rmse_i = root_mean_squared_error(target[:, i_out], simulation[:, i_out])\n",
    "            mae_i = mean_absolute_error(target[:, i_out], simulation[:, i_out])\n",
    "            mse.append(mse_i)\n",
    "            rmse.append(rmse_i)\n",
    "            mae.append(mae_i)    \n",
    "    else:\n",
    "        r2_scores.append(r2_score(target[:], simulation[:])) \n",
    "        mse.append(mean_squared_error(target[:], simulation[:]))\n",
    "        rmse.append(root_mean_squared_error(target[:], simulation[:]))\n",
    "        mae.append(mean_absolute_error(target[:], simulation[:]))\n",
    "    mean_mse = np.mean(mse)\n",
    "    if printScores:\n",
    "        for j_var, name in enumerate(var):\n",
    "            print(f\"Variable: {name}, mse: {mse[j_var]}\")\n",
    "            print(f\"Variable: {name}, rmse: {rmse[j_var]}\")\n",
    "            print(f\"Variable: {name}, mae: {mae[j_var]}\")\n",
    "            print(f\"Variable: {name}, r2: {r2_scores[j_var]}\")           \n",
    "    return r2_scores, mse, rmse, mae, mean_mse  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb0bec4-1467-40ce-a1b2-3f05c4d6ac58",
   "metadata": {},
   "source": [
    "# Pipeline for training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e446c-1245-4366-bbb9-2fb96771d956",
   "metadata": {},
   "source": [
    "The inputs are the following:\n",
    "- ScrapWeight,\n",
    "- StartTemperature\n",
    "- Argon\n",
    "- Energy\n",
    "- Starting chemical composition: LF_CA_ELEMENT_S\n",
    "- Chemical additions (in terms of the main elements added):\n",
    "    - Ca, F, Si, C, S, O, N, B, Al, Fe, P, Mg, Zn, Cu, V, Mn, Cr, Ti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7060fd4-f93a-4119-8b11-8024f5dcbef8",
   "metadata": {},
   "source": [
    "The possible targets are:\n",
    "- Final chemical composition: LF_CA_ELEMENT_F\n",
    "- Final temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b84ebf-7bef-4d70-911e-0705be918c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputVars_FL = ['ScrapWeight', 'StartTemperature', 'Argon', 'Energy', 'LF_CA_C_S', 'LF_CA_MN_S',\n",
    "                'LF_CA_SI_S', 'LF_CA_S_S', 'LF_CA_P_S', 'LF_CA_CA_S', 'LF_CA_AL_S', 'LF_CA_CU_S', 'LF_CA_V_S',\n",
    "                'LF_CA_PB_S', 'LF_CA_N_S', 'LF_CA_B_S', 'LF_CA_NB_S', 'LF_CA_SN_S', 'LF_CA_NI_S', 'LF_CA_CR_S', \n",
    "                'LF_CA_MO_S', 'LF_CA_TI_S', 'LF_CA_FE_S', 'Ca', 'F', 'Si', 'C', 'S', 'O', 'N', 'B', 'Al', 'Fe',\n",
    "                'P', 'Mg', 'Zn', 'Cu', 'V', 'Mn', 'Cr', 'Ti']\n",
    "\n",
    "TargetVars_FL = ['LF_CA_C_F', 'LF_CA_MN_F', 'LF_CA_SI_F', 'LF_CA_S_F', 'LF_CA_P_F', 'LF_CA_CA_F', \n",
    "                 'LF_CA_AL_F', 'LF_CA_CU_F', 'LF_CA_V_F', 'LF_CA_PB_F', 'LF_CA_N_F', 'LF_CA_B_F', \n",
    "                 'LF_CA_NB_F', 'LF_CA_SN_F', 'LF_CA_NI_F', 'LF_CA_CR_F', 'LF_CA_MO_F', 'LF_CA_TI_F',\n",
    "                 'LF_CA_FE_F', 'FinalTemperature']\n",
    "\n",
    "print(f'The number of Input variables is: {len(InputVars_FL)}')\n",
    "print(f'The number of Target variables is: {len(TargetVars_FL)}')\n",
    "\n",
    "excludedInputVars_FLmodel_chem = [] \n",
    "excludedtargetVars_FLmodel_chem = ['FinalTemperature']\n",
    "\n",
    "InputsVarsSelection_FLmodel_chem = [InElement for InElement in InputVars_FL if InElement not in excludedInputVars_FLmodel_chem]\n",
    "TargetVarsSelection_FLmodel_chem = [OutElement for OutElement in TargetVars_FL if OutElement not in excludedtargetVars_FLmodel_chem]\n",
    "\n",
    "print(f'The number of Input variables is: {len(InputsVarsSelection_FLmodel_chem)}')\n",
    "print(f'The number of Target variables is: {len(TargetVarsSelection_FLmodel_chem)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b669465-8853-494a-b7c2-5234ea69de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "dataset_path = \"\"\n",
    "\n",
    "dataset = pd.read_excel(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e283440-d719-4b2a-8efd-110bee40b92a",
   "metadata": {},
   "source": [
    "## Chemical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb715d85-708a-4976-ac7f-b688f65385d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the chemical model\n",
    "x = dataset[InputsVarsSelection_FLmodel_chem].values\n",
    "y = dataset[TargetVarsSelection_FLmodel_chem].values\n",
    "\n",
    "LFModelName = 'LF_chemicalModel_' + datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "xScaled, yScaled, inScaler, outScaler = scaleDataset(x, y, modelName=LFModelName)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(xScaled, yScaled, test_size=0.2)\n",
    "\n",
    "Neurons = [50, 40]\n",
    "model, modelHistory, minValLoss = train_seq_nn(xTrain, yTrain, Neurons, 'relu', LFModelName, verbosityLevel=0, lr=0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e6851-db94-48e9-b26b-c5942097993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the test dataset \n",
    "model_sim_test = use_model(model, xTest)\n",
    "out_test = outScaler.inverse_transform(model_sim_test)\n",
    "yTestDescaled = outScaler.inverse_transform(yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b9d0f-6424-42f8-8737-dbaf63340937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity plots of test dataset\n",
    "TargetVarsForPlot = ['Carbon (C)', 'Manganese (MN)', 'Silicon (SI)', 'Sulfur (S)', 'Phosphorus (P)', 'Calcium (CA)', 'Aluminum (AL)',  \n",
    "                     'Copper (CU)', 'Vanadium (V)', 'Lead (PB)', 'Nitrogen (N)', 'Boron (B)', 'Niobium (NB)', 'Tin (SN)', 'NIckel (NI)',  \n",
    "                     'Chromium (CR)', 'Molybdenum (MO)', 'Titanium (TI)', 'Iron (FE)']\n",
    "path_figures = r\"\"\n",
    "\n",
    "for i in range(yTestDescaled.shape[1]):\n",
    "    plotAndLinRegression(yTestDescaled[:, i], out_test[:, i], TargetVarsForPlot[i], savePlot=True, path=path_figures, fit_intercept_flag=True)\n",
    "    wait = input(\"Press Enter to continue.\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b356da46-d7f7-4f24-ac28-25ab711f7b61",
   "metadata": {},
   "source": [
    "## temperature model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5edb504-e4a0-4fe2-a0bf-3662aa81a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "optVars_temp = ['ScrapWeight', 'StartTemperature', 'Argon', 'Energy', 'LF_CA_MN_S', 'LF_CA_S_S', 'LF_CA_P_S',\n",
    "                'LF_CA_CA_S', 'LF_CA_V_S', 'LF_CA_B_S', 'LF_CA_NB_S', 'LF_CA_SN_S', 'LF_CA_NI_S', 'LF_CA_CR_S',\n",
    "                'LF_CA_FE_S', 'S', 'C', 'N', 'P', 'Fe', 'V', 'Ca', 'Mg', 'F']\n",
    "\n",
    "x_temp = dataset_france[optVars_temp].values\n",
    "y_temp = dataset_france['FinalTemperature'].values.reshape(-1, 1)\n",
    "\n",
    "LFModelName_temp = 'LF_optim_temp_' + datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "xScaled_temp, yScaled_temp, inScaler_temp, outScaler_temp = scaleDataset(x_temp, y_temp, modelName=LFModelName_temp)\n",
    "\n",
    "xTrain_temp, xTest_temp, yTrain_temp, yTest_temp = train_test_split(xScaled_temp, yScaled_temp, test_size=0.2)\n",
    "\n",
    "Neurons_temp = [20, 5]\n",
    "tempModel_optimized, modelHistory_temp, minValLoss_temp = train_seq_nn(xTrain_temp, yTrain_temp, Neurons_temp, 'relu', LFModelName_temp, verbosityLevel=0, lr=0.0001, validationSplit=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8b012c-2014-4328-a1fb-cc5badc932ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempModel_sim_test = use_model(tempModel_optimized, xTest_temp)\n",
    "tempModel_out_test = outScaler_temp.inverse_transform(tempModel_sim_test)\n",
    "yTestDescaled_temp = outScaler_temp.inverse_transform(yTest_temp)\n",
    "\n",
    "TargetVarsForPlot = 'Steel temperature (LF)'\n",
    "pathFiguresLFModel_2 = r\"\"\n",
    "\n",
    "plotAndLinRegression(yTestDescaled_temp[:, 0], tempModel_out_test[:, 0], TargetVarsForPlot, savePlot=True, path=pathFiguresLFModel_2, fit_intercept_flag=True)\n",
    "\n",
    "mse_TempModel = mean_squared_error(yTestDescaled_temp[:, 0], tempModel_out_test[:, 0])\n",
    "rmse_TempModel = np.sqrt(mse_TempModel)\n",
    "print(f\"RMSE of temperature model (test dataset): {rmse_TempModel} Â°C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39a5cf-9f48-4ea6-b397-cf4c2688af50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
